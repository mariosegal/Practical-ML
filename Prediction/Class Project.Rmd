---
title: "Class Project Practical Machine Learning Class Coursera- Mario Segal"
author: "Mario Segal"
date: "July 24, 2014"
output: html_document
---

##This is the code for my Parctical Machine Larning Project

***Load Required Libraries***
```{r,warning=FALSE}
require(caret)
require(rattle)
```

***Load and Clean the Data***
```{r, echo=FALSE,warning=FALSE}
columns <- c("character","factor","date","Date","character","factor",rep("numeric",153),"factor")
train_raw <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),header=T,strip.white=T,stringsAsFactors=F)
test_raw <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),header=T,strip.white=T,stringsAsFactors=F)

#the data was imported as character in many cases and that is incorrect, let's fix that
#for now colums 6-159 should be numeric
train <- train_raw
bad <- which(sapply(train,is.character))
train[bad[4:36]] <- lapply(train[bad[4:36]],as.numeric)

test <- test_raw
bad1 <- which(sapply(test,is.character))
#no need to convert the test as it looks fine
```

***Explore the Data with Some Nice Charts***
```{r,warning=FALSE}
library(ggplot2); library(gridExtra)
vars <- setdiff(which(sapply(train, function(x) sum(!is.na(x))>0)),1:8)
pdf("Exploratory Charts v1.pdf",width=11,height = 8)
for (i in 1:length(vars)) {
    ch <- ggplot(train,aes_string(x=names(train)[160],fill=names(train)[160],y=names(train)[vars[i]]))+theme_bw()+
      geom_jitter(color="blue",position = position_jitter(width = .1),size=1)+theme(legend.position="none")+ 
      geom_boxplot(alpha=0.5)
 print(ch)
}
dev.off()
```

***Explore the Data with Some Nice Charts***
```{r,warning=FALSE}
# most varibles are either complete or mostly missing
#I will chose to take the ones with full data
#It turns out the summary variables were very sparse and I am supressing those
full_vars <- which(sapply(train,function(x) sum(is.na(x)))==0)
full_vars <- full_vars[-(1:7)]

train_full <- subset(train,,full_vars)
nearZeroVar(train_full)  #good they have no NAs and have proper variance
```

***Check for Highly Correlated Variables, using Approach from Professor Leek***
```{r,warning=FALSE}
groups <- c("_belt","_arm","_dumbbell","_forearm")

#Check for highly correlated matrices as per Prof. Leek in the lecture
M <- abs(cor(train_full[which(grepl(groups[1],names(train_full)))]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
#I see a lot of correlation for belt

M <- abs(cor(train_full[which(grepl(groups[2],names(train_full)))]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
#I see some  correlation for arm

M <- abs(cor(train_full[which(grepl(groups[3],names(train_full)))]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
#I see some  correlation for dumbbell

M <- abs(cor(train_full[which(grepl(groups[4],names(train_full)))]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
#I see very little for forearm
```

***Reduce Dimensions using PCA by Sensor***
```{r,warning=FALSE}
#create PC's for each sensor
pc_belt <- preProcess(train_full[which(grepl(groups[1],names(train_full)))],method="pca")
pc_belt1 <- predict(pc_belt,train_full[which(grepl(groups[1],names(train_full)))])
names(pc_belt1) <- tolower(paste(names(pc_belt1),groups[1],sep=""))

pc_arm <- preProcess(train_full[which(grepl(groups[2],names(train_full)))],method="pca")
pc_arm1 <- predict(pc_arm,train_full[which(grepl(groups[2],names(train_full)))])
names(pc_arm1) <- tolower(paste(names(pc_arm1),groups[2],sep=""))

pc_dumbbell <- preProcess(train_full[which(grepl(groups[3],names(train_full)))],method="pca")
pc_dumbbell1 <- predict(pc_dumbbell,train_full[which(grepl(groups[3],names(train_full)))])
names(pc_dumbbell1) <- tolower(paste(names(pc_dumbbell1),groups[3],sep=""))

pc_forearm <- preProcess(train_full[which(grepl(groups[4],names(train_full)))],method="pca")
pc_forearm1 <- predict(pc_forearm,train_full[which(grepl(groups[4],names(train_full)))])
names(pc_forearm1) <- tolower(paste(names(pc_forearm1),groups[4],sep=""))
```

***Visualize First 2 PCs per Group***
```{r,warning=FALSE}
print(ggplot(pc_arm1,aes(x=pc1_arm,y=pc2_arm,color=train_full$classe))+geom_point()+ggtitle("Arm"))
print(ggplot(pc_dumbbell1,aes(x=pc1_dumbbell,y=pc2_dumbbell,color=train_full$classe))+geom_point()+
        coord_cartesian(ylim=c(0,10))+ggtitle("Dumbbell"))
print(ggplot(pc_belt1,aes(x=pc1_belt,y=pc2_belt,color=train_full$classe))+geom_point()+ggtitle("Belt"))
print(ggplot(pc_forearm1,aes(x=pc1_forearm,y=pc2_forearm,color=train_full$classe))+geom_point()+
        coord_cartesian(ylim=c(-5,5))+ggtitle("Forearm"))
#The charts seem to group but not perfectly
```

***Combine PCs together and also Apply the PCs to test set for Eventual Prediction***
```{r,warning=FALSE}
#combine all the PCs into an analysis set
train_pc <- data.frame(cbind(pc_belt1,pc_arm1,pc_dumbbell1,pc_forearm1),classe=train_full$classe)

#Apply the PCS to test set;
test_pc_arm <- predict(pc_arm,newdata=test[row.names(pc_arm$rotation)])
names(test_pc_arm) <- tolower(paste(names(test_pc_arm),"_arm",sep=""))
test_pc_forearm <- predict(pc_forearm,newdata=test[row.names(pc_forearm$rotation)])
names(test_pc_forearm) <- tolower(paste(names(test_pc_forearm),"_forearm",sep=""))
test_pc_dumbbell <- predict(pc_dumbbell,newdata=test[row.names(pc_dumbbell$rotation)])
names(test_pc_dumbbell) <- tolower(paste(names(test_pc_dumbbell),"_dumbbell",sep=""))
test_pc_belt <- predict(pc_belt,newdata=test[row.names(pc_belt$rotation)])
names(test_pc_belt) <- tolower(paste(names(test_pc_belt),"_belt",sep=""))

test_pc <- data.frame(cbind(test_pc_arm,test_pc_belt,test_pc_dumbbell,test_pc_forearm))
```

***Start Modeling Process***
```{r,warning=FALSE}
#Always a good idea to start with a tree
model1 <- train(classe~.,data=train_pc,method="rpart") 
model1$finalModel   
fancyRpartPlot(model1$finalModel) #this did not work at all as it is not predicting C or E
confusionMatrix(predict(model1,train_pc),train_pc$classe)
```